ENCODER_MODEL_MAPPING = {
    # Mapping of encoder names to Hugging Face model names
    # Add more here if needed
    "clip-vit-base-patch16-224-in21k": "laion/CLIP-ViT-H-14-laion2B-s32B-b79K",
    "clip-vit-base-patch16": "openai/clip-vit-base-patch16",
    "clip-vit-base-patch32": "openai/clip-vit-base-patch32",
    "CLIP-ViT-bigG-14-laion2B-39B-b160k": "laion/CLIP-ViT-bigG-14-laion2B-39B-b160k",
    "clip-vit-large-patch14-336": "openai/clip-vit-large-patch14-336",
    "clip-vit-large-patch14": "openai/clip-vit-large-patch14",
    "t5-small": "google-t5/t5-small",
    "t5-v1_1-xxl": "google/t5-v1_1-xxl",
}
